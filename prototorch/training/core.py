import time
from collections import defaultdict

import torch

from prototorch.training.utils import isnumeric


class BaseMetricsContainer:
    def update(self):
        raise NotImplementedError()

    def values(self):
        raise NotImplementedError()

    def print_values(self, epoch, batch_ix):
        running_metrics = self.values()
        running_metrics_msg = "  ".join([f"{m}: {v} " for m, v in running_metrics.items()])
        print(
            f"[{epoch or -1:d}, {batch_ix+1:5d}, ({self.total_seen}) datapoints] "
            + running_metrics_msg,
            flush=True,
        )


class AcceleratorMetricsContainer(BaseMetricsContainer):

    """
    TODO: implement reduce_for_metrics / raise issue in accelerate.
    """

    def __init__(self, accelerator):
        self.accelerator = accelerator
        self.total_seen = 0
        self.metrics_totals = defaultdict(int)
        self.metrics_total_seen = defaultdict(int)

    def update(self, batch_metrics, batch_size):
        for m, v in batch_metrics.items():
            assert isinstance(v, torch.Tensor) and isinstance(batch_size, torch.Tensor), f"{m} should be tensor but is {v}"
            self.metrics_totals[m] += v.detach() * batch_size
            self.metrics_total_seen[m] += batch_size

        self.total_seen += batch_size

    def values(self):
        # n.b. reduce is not inplace, explicitly first clones tensor then performs in-place reduction on clone.
        return {
            m: self.accelerator.reduce(v).item() / self.accelerator.reduce(self.metrics_total_seen[m]).item()
            for m, v in self.metrics_totals.items()
        }

    def print_values(self, epoch, batch_ix):
        running_metrics = self.values()
        running_metrics_msg = "  ".join([f"{m}: {v} " for m, v in running_metrics.items()])
        if self.accelerator.is_main_process:
            # super().print_values(epoch, batch_ix)  - doing this seemed to get things out of sync
            print(
                f"[{epoch or -1:d}, {batch_ix+1:5d}, ({self.total_seen}) datapoints] "
                + running_metrics_msg,
                flush=True,
            )


class ScalarAverageMetricsContainer(BaseMetricsContainer):

    """Loss-associated metrics which should be averaged over samples.

    values() returns running_metrics.
    """

    def __init__(self):
        self.total_seen = 0
        self.metrics_totals = defaultdict(int)
        self.metrics_total_seen = defaultdict(int)

    def update(self, batch_metrics, batch_size):
        for m, v in batch_metrics.items():
            if isinstance(v, torch.Tensor):
                # we don't want tensors as they will create computation graphs
                # https://blog.paperspace.com/pytorch-memory-multi-gpu-debugging/
                # raise ValueError()
                v = v.item()
            if isnumeric(v):
                self.metrics_totals[m] += v * batch_size
                self.metrics_total_seen[m] += batch_size

        self.total_seen += batch_size

    def values(self):
        return {m: v / self.metrics_total_seen[m] for m, v in self.metrics_totals.items()}


def test_loop(
    learner,
    data_loader,
    verbose=False,
    prefix="",
    test_run=False,
):
    """Test loop.

    Steps through all batches in data loader and accumulates metrics.
    N.B. only accumulates metrics generated by calling learner.test_step;
    other metrics may require calls to different learner methods and
    should be handled separately as evaluators.
    """
    learner.test_begin()
    if learner.accelerator is not None:
        metrics_container = AcceleratorMetricsContainer(learner.accelerator)
    else:
        metrics_container = ScalarAverageMetricsContainer()

    for i, batch in enumerate(data_loader):
        # TODO - need to handle this differently
        batch_size = learner.get_batch_size(batch)

        batch_metrics = learner.test_step(
            batch,
        )  # TODO handle the effective_batch_size correction outside of train step
        batch_metrics = {f"val/{prefix}" + k: v for k, v in batch_metrics.items()}
        # SEQUENCE / DATAPOINT LEVEL METRICS
        metrics_container.update(batch_metrics, batch_size)

        if test_run:
            break

    metrics = (
        metrics_container.values()
    )  # n.b. dont add time to avoid conflict. or if do prefix with val.

    return metrics


def epoch_train(
    learner,
    data_loader,
    verbose=False,
    epoch=None,
    batch_log_freq=500,
    logger=None,
    test_run=False,
):
    """Single epoch training loop. Assumes learner handles gradient updates.

    Steps through all batches in data loader, updates parameters,
    accumulates and prints metrics, and writes model checkpoints.
    """
    t0 = time.time()
    learner.epoch_begin()

    if learner.accelerator is not None:
        metrics_container = AcceleratorMetricsContainer(learner.accelerator)
    else:
        metrics_container = ScalarAverageMetricsContainer()

    t0 = time.time()
    for i, batch in enumerate(data_loader):
        batch_metrics = learner.train_step(batch)

        # SEQUENCE / DATAPOINT LEVEL METRICS
        batch_size = learner.get_batch_size(batch)
        metrics_container.update(batch_metrics, batch_size)

        if batch_log_freq is not None and (i % batch_log_freq == (batch_log_freq - 1)) or test_run:
            t1 = time.time()
            metrics_container.print_values(epoch, i)
            print(f"Time to complete {batch_log_freq} batches", t1-t0, flush=True)
            t0 = t1
            # if logger is not None:
            #     logger.log(epoch, batch_metrics, batch=i)

        if test_run:
            break

    t1 = time.time()

    end_metrics = {f"train/{k}": v for k, v in metrics_container.values().items()}
    end_metrics["train/time(s)"] = t1 - t0
    learner.epoch_end()

    return end_metrics


def train(
    learner,
    train_loader,
    validation_loader,
    epochs=100,
    val_freq=1,
    logger=None,
    start_epoch=0,
    output_dir=None,
    checkpoint_freq=1,
    batch_log_freq=500,
    evaluators=None,
    test_run=False,
):
    learner.train_begin()  # consider whether or not we want this - resume...
    evaluators = evaluators or []
    hist = []
    for epoch in range(epochs):
        metrics = epoch_train(
            learner,
            train_loader,
            epoch=epoch,
            batch_log_freq=batch_log_freq,
            logger=logger,
            test_run=test_run,
        )
        is_val_epoch = epoch % val_freq == 0 or epoch == epochs - 1
        if val_freq is not None and validation_loader is not None and is_val_epoch:
            with torch.no_grad():
                metrics.update(
                    test_loop(
                        learner,
                        validation_loader,
                        test_run=test_run,
                    )
                )
                for evaluator in evaluators:
                    metrics.update(evaluator(learner))
        hist.append(metrics)
        if logger is not None:
            logger.log(epoch + start_epoch, metrics, batch=-1)

        if epoch % checkpoint_freq == 0 and output_dir is not None:
            learner.checkpoint(output_dir, epoch)

    return hist
